{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ERIN O'CONNELL \n",
    "#  AIS Workflow using 1 day of sample data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial Data Cleaning Notes: \n",
    "\n",
    "Draught Column: many 0 values\n",
    "\n",
    "Change in Draught: all 0 values once subsetted to darkvess, making the binary change column redundant \n",
    "\n",
    "Lat/lon Column: many 0 values, some values over 90 and over 180\n",
    "\n",
    "MMSI: I used this as a unique_id field for all the ships rather than the ‘name’ field\n",
    "\n",
    "Lat/lon: also had issues with many trailing decimals\n",
    "\n",
    "Making sure columns are recognized as numeric, POSix, date time formatting. Normally, I would start with subsetting rows by geographic location clip, but because that wasn’t working I knew I needed to focus on cleaning data first\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment Installation if Needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Python 3.11.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rasterio\n",
      "  Downloading rasterio-1.3.10-cp311-cp311-macosx_11_0_arm64.whl.metadata (14 kB)\n",
      "Collecting affine (from rasterio)\n",
      "  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs in /opt/anaconda3/lib/python3.11/site-packages (from rasterio) (23.2.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.11/site-packages (from rasterio) (2024.2.2)\n",
      "Requirement already satisfied: click>=4.0 in /opt/anaconda3/lib/python3.11/site-packages (from rasterio) (8.1.7)\n",
      "Collecting cligj>=0.5 (from rasterio)\n",
      "  Downloading cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.11/site-packages (from rasterio) (1.26.4)\n",
      "Collecting snuggs>=1.4.1 (from rasterio)\n",
      "  Downloading snuggs-1.4.7-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting click-plugins (from rasterio)\n",
      "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.11/site-packages (from rasterio) (68.2.2)\n",
      "Requirement already satisfied: pyparsing>=2.1.6 in /opt/anaconda3/lib/python3.11/site-packages (from snuggs>=1.4.1->rasterio) (3.0.9)\n",
      "Downloading rasterio-1.3.10-cp311-cp311-macosx_11_0_arm64.whl (18.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
      "Downloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
      "Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
      "Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
      "Installing collected packages: snuggs, cligj, click-plugins, affine, rasterio\n",
      "Successfully installed affine-2.4.0 click-plugins-1.1.1 cligj-0.7.2 rasterio-1.3.10 snuggs-1.4.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting geopandas\n",
      "  Downloading geopandas-0.14.4-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting fiona>=1.8.21 (from geopandas)\n",
      "  Downloading fiona-1.9.6-cp311-cp311-macosx_11_0_arm64.whl.metadata (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.22 in /opt/anaconda3/lib/python3.11/site-packages (from geopandas) (1.26.4)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.11/site-packages (from geopandas) (23.1)\n",
      "Requirement already satisfied: pandas>=1.4.0 in /opt/anaconda3/lib/python3.11/site-packages (from geopandas) (2.1.4)\n",
      "Requirement already satisfied: pyproj>=3.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from geopandas) (3.6.1)\n",
      "Requirement already satisfied: shapely>=1.8.0 in /opt/anaconda3/lib/python3.11/site-packages (from geopandas) (2.0.4)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from fiona>=1.8.21->geopandas) (23.2.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.11/site-packages (from fiona>=1.8.21->geopandas) (2024.2.2)\n",
      "Requirement already satisfied: click~=8.0 in /opt/anaconda3/lib/python3.11/site-packages (from fiona>=1.8.21->geopandas) (8.1.7)\n",
      "Requirement already satisfied: click-plugins>=1.0 in /opt/anaconda3/lib/python3.11/site-packages (from fiona>=1.8.21->geopandas) (1.1.1)\n",
      "Requirement already satisfied: cligj>=0.5 in /opt/anaconda3/lib/python3.11/site-packages (from fiona>=1.8.21->geopandas) (0.7.2)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.11/site-packages (from fiona>=1.8.21->geopandas) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.11/site-packages (from pandas>=1.4.0->geopandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas>=1.4.0->geopandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas>=1.4.0->geopandas) (2023.3)\n",
      "Downloading geopandas-0.14.4-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fiona-1.9.6-cp311-cp311-macosx_11_0_arm64.whl (13.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.9/13.9 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: fiona, geopandas\n",
      "Successfully installed fiona-1.9.6 geopandas-0.14.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get your packages\n",
    "import os\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# (NOTE:this is currently hardcoded but could be changed to access GCS bucket using gcloud API)\n",
    "# Uncommment these lines if data is not already in project directory\n",
    "\n",
    "#ais = gpd.read_file('/Users/kale/Downloads/ais_test/ais_sample.csv')\n",
    "\n",
    "# Load EEZ\n",
    "#eez = gpd.read_file('/Users/kale/Downloads/ais_test/iran_eez.geojson')\n",
    "#print(type(eez))\n",
    "\n",
    "# Load TTW\n",
    "#ttw = gpd.read_file('/Users/kale/Downloads/ais_test/iran_ttw.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate Change in Draught Column ####\n",
    "\n",
    "# Convert 'draught' column to numeric\n",
    "ais['draught'] = pd.to_numeric(ais['draught'])\n",
    "\n",
    "# Arrange dataframe by 'mmsi' and 'timestamp'\n",
    "ais = ais.sort_values(by=['mmsi', 'timestamp'])\n",
    "\n",
    "# Calculate change in draught by grouping by 'mmsi' and store it in new column, change_in_draught\n",
    "ais['change_in_draught'] = ais.groupby('mmsi')['draught'].diff()\n",
    "\n",
    "# Ungroup the dataframe\n",
    "ais = ais.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate lag time between AIS transmisison ####\n",
    "\n",
    "# Sort by mmsi and timestamp column\n",
    "ais['timestamp'] = pd.to_datetime(ais['timestamp'])\n",
    "ais = ais.sort_values(by=['mmsi', 'timestamp'])\n",
    "ais['time_diff'] = ais.groupby('mmsi')['timestamp'].diff()\n",
    "\n",
    "# Convert time difference column from seconds to hours\n",
    "ais['time_diff_hours'] = ais['time_diff'] / 3600\n",
    "\n",
    "# Remove 'secs' from the values in ais['time_diff_hours']\n",
    "ais['time_diff_hours'] = ais['time_diff_hours'].replace('secs', '', regex=True)\n",
    "\n",
    "# Convert the column to numeric (if it's not already)\n",
    "ais['time_diff_hours'] = pd.to_numeric(ais['time_diff_hours'])\n",
    "\n",
    "# Subset rows where time difference is equal to or greater than 6 hours and store this in darkvessles obj\n",
    "darkvessels = ais[ais['time_diff_hours'] >= 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Checking IDs of dark vessels ####\n",
    "\n",
    "# Get unique IDs excluding NA\n",
    "ids = darkvessels['mmsi'].dropna().unique()\n",
    "\n",
    "# Subset based on the ID vector just created\n",
    "sub_df = darkvessels[darkvessels['mmsi'].isin(ids)]\n",
    "\n",
    "# Another way to cross-check this subset by complete cases\n",
    "t = darkvessels[darkvessels['mmsi'].notna()]\n",
    "\n",
    "# Creates vector of unique vessel IDs can be useful later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Filtering and Cleaning ####\n",
    "\n",
    "# Remove rows without a value for lon\n",
    "t = t[t['longitude'].notna() & (t['longitude'] != '')]\n",
    "\n",
    "# Remove rows with invalid latitude and longitude values\n",
    "t = t[(t['latitude'] <= 91) & (t['longitude'] <= 180)]\n",
    "\n",
    "# Brute force removed a specific outlier\n",
    "t = t[t['mmsi'] != 352003189]\n",
    "\n",
    "# Clean Coordinates Trailing Decimals trim to 5\n",
    "t['latitude'] = t['latitude'].astype(float).round(5)\n",
    "t['longitude'] = t['longitude'].astype(float).round(5)\n",
    "\n",
    "# Create Change in Draught Binary Column\n",
    "t['draught_change'] = 0\n",
    "t.loc[t['change_in_draught'].notna() & (t['change_in_draught'] != ''), 'draught_change'] = 1\n",
    "\n",
    "# Create a new dataframe with specific columns we want \n",
    "cleaned_csv = t[['mmsi', 'timestamp', 'latitude', 'longitude', 'draught_change', 'time_diff_hours']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Subset Dark Vessels based on Location ####\n",
    "\n",
    "# Filter based on input vector data using geopandas\n",
    "eez = gpd.read_file(\"/Users/kale/Downloads/ais_test/iran_eez.geojson\")\n",
    "ttw = gpd.read_file(\"/Users/kale/Downloads/ais_test/iran_ttw.geojson\")\n",
    "\n",
    "# Convert cleaned_csv to a GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(cleaned_csv, geometry=gpd.points_from_xy(cleaned_csv.longitude, cleaned_csv.latitude), crs=\"EPSG:4326\")\n",
    "\n",
    "# Are both layers in the same CRS? Check this for both ttw and eez\n",
    "if (eez.crs == gdf.crs):\n",
    "    print(\"Both layers are in the same crs!\",\n",
    "          eez.crs, gdf.crs)\n",
    "\n",
    "# Clip vessels to boundary \n",
    "v_eez = gpd.overlay(gdf, eez, how='intersection')\n",
    "v_ttw = gpd.overlay(gdf, ttw, how='intersection')\n",
    "\n",
    "### Notes:\n",
    "# Can use clip, intersection, contains, depending on desired output\n",
    "# Always make sure crs === crs, datumn, extents match, resolutions match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Cleaning and Export of CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract coordinates Formatting for Export\n",
    "eez_csv = v_eez.assign(Latitude=v_eez.geometry.y, Longitude=v_eez.geometry.x).drop(columns=['geometry'])\n",
    "ttw_csv = v_ttw.assign(Latitude=v_ttw.geometry.y, Longitude=v_ttw.geometry.x).drop(columns=['geometry'])\n",
    "\n",
    "# Write csv to filepath\n",
    "eez_csv.to_csv(\"eez_vessels.csv\", index=False)\n",
    "ttw_csv.to_csv(\"ttw_vessels.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   # NOTES: \n",
    "    # many of the draught columns are filled with 0, so when\n",
    "    # I subsetted down to the dark vessels none of them have draught\n",
    "    # values meaning the draught difference is also 0, therefore\n",
    "    # making the binary draught column all 0\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Part 3:How would you expand your solution to predict where a dark vessel went during its period of darkness?\n",
    "\n",
    "To solve this issue, I would interpolate from previous vessel movements. I have done this with animal movement data. To do this, I used a distribution of previous movement metrics: turning angle, speed, position, environmental predictors etc. I could also create tracks of vessels.\n",
    "\n",
    "I would also incorperate ML: training/validation subset 70/30 split\n",
    "\n",
    "Ideas: regression trees, cnns(neural nets), hypertune parameters or our predictors of vessel movement \n",
    "\n",
    "\n",
    "I would need data from movement metrics and other environmental predictors.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GIS712",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
